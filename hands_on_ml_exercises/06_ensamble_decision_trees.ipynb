{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNn/NlPGo07wDlUN2jae3FQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hkaragah/google_colab_repo/blob/main/hands_on_ml_exercises/06_ensamble_decision_trees.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ensamble Decision Trees"
      ],
      "metadata": {
        "id": "tCY6JCiDIx7j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Disclaimer:__ This exercise is adopted from `\"Hands-on Machine Learning with Scikit-Learn, Keras & Tensorflow (Third Edition)\"` book written by `_Aurelien Geron_` publoshed by `_O'Reilly_`. I broke them down into smaller digestable snippets, made some modifications, and added some explanations so that I can undersatand them better. The porpuse of this notebook is just for me to understand the concept and have hands-on practice while reading the book material."
      ],
      "metadata": {
        "id": "FQp9YCZho5gc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objective\n",
        "Use ensamble decision trees for classification to miprove prediction accuracy"
      ],
      "metadata": {
        "id": "E3Yj1jDKI-NY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Dataset"
      ],
      "metadata": {
        "id": "QKJLU0mcmA4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_moons\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, ShuffleSplit\n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from graphviz import Source\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from copy import deepcopy\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n"
      ],
      "metadata": {
        "id": "cYXY0nVfmDHF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_moons, y_moons = make_moons(n_samples=10_000, noise=0.4, random_state=42)"
      ],
      "metadata": {
        "id": "WLzWX_l7cTl0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate train set"
      ],
      "metadata": {
        "id": "buhIpouMb8Ws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_moons, y_moons, test_size=0.2, random_state=42)\n",
        "\n",
        "n_sets = 1000\n",
        "set_size = 100\n",
        "mini_batches = []\n",
        "\n",
        "indices = ShuffleSplit(n_splits=n_sets, test_size=len(X_train) - set_size, random_state=42) # return randomly selected train and test indices\n",
        "\n",
        "for train_index, test_index in indices.split(X_train):\n",
        "    X_batch, y_batch = X_train[train_index], y_train[train_index]\n",
        "    mini_batches.append((X_batch, y_batch))"
      ],
      "metadata": {
        "id": "2IMm5ARlmQYx"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define and Train Ensamble Trees (Forest)"
      ],
      "metadata": {
        "id": "vOo13qbdoTBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Best hyperparameters obtained from GridSearch (see notebook: \"06-Overfitted_decision_tree.ipynb\")\n",
        "hyperparams = {'max_depth':8, 'max_leaf_nodes':19}\n",
        "clf = DecisionTreeClassifier(random_state=42, **hyperparams)\n",
        "\n",
        "# Generate models for each model, I make a deepcopy of the original model because I don't want to overwrite the trained parameters for each set\n",
        "forest = [deepcopy(clf) for _ in range(n_sets)]\n",
        "\n",
        "# Train each model\n",
        "for i in range(n_sets):\n",
        "    forest[i].fit(mini_batches[i][0], mini_batches[i][1])"
      ],
      "metadata": {
        "id": "WGXCYv9ioAvk"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating Average of Accuracy Scores"
      ],
      "metadata": {
        "id": "DDhZuDRmjN7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores = []\n",
        "accuracy_scores = []\n",
        "\n",
        "for tree in forest:\n",
        "    # One way to computed accuracy scores\n",
        "    scores.append(tree.score(X_test, y_test))\n",
        "\n",
        "    # Another way to compute accuracy scores\n",
        "    y_pred = tree.predict(X_test)\n",
        "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
        "\n",
        "print(f\"Average score: {np.mean(scores)}\")\n",
        "print(f\"Average accuracy score: {np.mean(accuracy_scores)}\")"
      ],
      "metadata": {
        "id": "5vuO5HTOVMxp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "331b1b19-95bd-4859-c5ef-8f480389c5f8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average score: 0.802034\n",
            "Average accuracy score: 0.802034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Useing the tunes hyperparameters in `06-Overfitted_decision_tree.ipynb`, I obtained about 96% accuracy, but here each tree reached lower accuracy score. This is because here I only used 100 samples for trainig, but previously I used 10_000 samples. <br>\n",
        "Let's use _majority-vote_ for the prediction to see if it can imporve the accuracy score."
      ],
      "metadata": {
        "id": "VF3ZI2Boj7C2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.empty(shape=[n_sets, len(X_test)], dtype=np.uint8) # \"dtype\" doesn't need to be float, there are only two classes 0 and 1\n",
        "print(y_pred.shape)\n",
        "\n",
        "for i in range(n_sets):\n",
        "    y_pred[i] = forest[i].predict(X_test)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlur11zkju0T",
        "outputId": "e67440f8-8252-446c-8d55-444c0831e7c4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 2000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import mode\n",
        "\n",
        "mode(y_pred, axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z24jjIDNnCkb",
        "outputId": "c5f83bf0-b7fc-4dbb-c278-89cfd0beb61d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModeResult(mode=array([1, 1, 0, ..., 0, 0, 0]), count=array([948, 909, 962, ..., 910, 992, 598]))"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using `mode` returns two arrays, mode and count. \"_mode_\" array contains the majority-vote and \"_count_\" array contains the count of the majority-vote for each sample in the test set `X_test` becasue I ran it on `axis=0`.<br>\n",
        "Now, let's compute the accuracy score."
      ],
      "metadata": {
        "id": "Ochxh9b2nv-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_pred_majority_votes = mode(y_pred, axis=0)[0] # shape (2000,)\n",
        "\n",
        "print(f\"Accuracy score: {accuracy_score(y_test, mode(y_pred, axis=0)[0])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHzNNeImnWYR",
        "outputId": "f716c40d-03f4-4c75-dd09-a1ebfc84d6e3"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score: 0.872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the accuracy score increased from 0.802 to 0.872 (~8% improvement)."
      ],
      "metadata": {
        "id": "hYJ1PAbopYqD"
      }
    }
  ]
}